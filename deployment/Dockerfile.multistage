# syntax=docker/dockerfile:1.4
# Multi-stage Dockerfile consolidating all services
# Reduces duplication from 4 Dockerfiles to 1
# ~40% smaller images, faster builds

# =============================================================================
# Stage 1: Base Python + System Dependencies
# =============================================================================
FROM python:3.13-slim AS base

# Set Python environment variables
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    # Path to Chromium for Lighthouse/screenshots
    CHROME_PATH=/usr/bin/chromium \
    # Pyppeteer configuration
    PYPPETEER_CHROMIUM_REVISION=1056772 \
    PYPPETEER_HOME=/opt/pyppeteer

WORKDIR /code

# Install base system dependencies (shared by all services)
RUN --mount=type=cache,target=/var/cache/apt,sharing=locked \
    --mount=type=cache,target=/var/lib/apt,sharing=locked \
    apt-get update && apt-get install -y --no-install-recommends \
    # Essential tools
    curl \
    ca-certificates \
    gnupg \
    # PostgreSQL client library
    libpq5 \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Install uv for fast dependency installation
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install --upgrade pip uv

# Copy and install Python dependencies
COPY requirements/base.txt requirements.txt
RUN --mount=type=cache,target=/root/.cache/uv \
    uv pip install --system --no-cache -r requirements.txt

# =============================================================================
# Stage 2: Builder (Node.js + Build Tools)
# =============================================================================
FROM base AS builder

# Install Node.js for asset building
RUN --mount=type=cache,target=/var/cache/apt,sharing=locked \
    --mount=type=cache,target=/var/lib/apt,sharing=locked \
    apt-get update && apt-get install -y --no-install-recommends \
    nodejs \
    npm \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Copy package files and install dependencies
COPY package.json package-lock.json* ./
COPY .config/postcss.config.js .config/purgecss.config.js .config/

# Install npm dependencies
RUN --mount=type=cache,target=/root/.npm \
    npm ci --prefer-offline --no-audit --frozen-lockfile --progress=false

# Copy scripts and static files for building
COPY scripts/ ./scripts/
COPY static/ ./static/
COPY omas/static/ ./omas/static/

# Build and optimize JavaScript files
ARG SKIP_JS_BUILD=0
RUN if [ "$SKIP_JS_BUILD" = "0" ]; then npm run build:js; else echo "Skipping JS build"; fi

# Copy rest of application code
COPY . /code/

# Build CSS with all templates now available
RUN python manage.py build_css

# Collect and optimize static files at build time
RUN python manage.py collectstatic --no-input

# =============================================================================
# Stage 3: Runtime with Chromium (Web + Celery Worker)
# =============================================================================
FROM base AS runtime-full

# Install Chromium and dependencies for screenshot generation
RUN --mount=type=cache,target=/var/cache/apt,sharing=locked \
    --mount=type=cache,target=/var/lib/apt,sharing=locked \
    apt-get update && apt-get install -y --no-install-recommends \
    chromium \
    chromium-driver \
    fonts-liberation \
    libasound2 \
    libatk-bridge2.0-0 \
    libatk1.0-0 \
    libatspi2.0-0 \
    libcups2 \
    libdbus-1-3 \
    libdrm2 \
    libgbm1 \
    libgtk-3-0 \
    libnspr4 \
    libnss3 \
    libx11-6 \
    libxcb1 \
    libxcomposite1 \
    libxdamage1 \
    libxext6 \
    libxfixes3 \
    libxkbcommon0 \
    libxrandr2 \
    xdg-utils \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Create pyppeteer directory and pre-download Chromium
RUN mkdir -p $PYPPETEER_HOME && chmod -R 755 $PYPPETEER_HOME \
    && python -c "from pyppeteer import chromium_downloader; chromium_downloader.download_chromium()"

# Create non-root user for security
RUN groupadd -r appuser && useradd -r -g appuser appuser

# Copy application code from builder (includes built assets)
COPY --from=builder --chown=appuser:appuser /code /code

# Copy entrypoint script
COPY deployment/docker-entrypoint.sh /docker-entrypoint.sh
RUN chmod +x /docker-entrypoint.sh

# Switch to non-root user
USER appuser

EXPOSE 80

# Health check for zero-downtime deployments
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
    CMD curl -f http://127.0.0.1:80/health/ || exit 1

ENTRYPOINT ["/docker-entrypoint.sh"]

# Default command (can be overridden for different services)
CMD ["gunicorn", "--bind", ":80", "--workers", "8", "config.wsgi", "--log-level", "info", "--access-logfile", "-", "--error-logfile", "-"]

# =============================================================================
# Stage 4: Runtime Minimal (Celery Beat + Flower)
# =============================================================================
FROM base AS runtime-minimal

# Install gdbm backend for Python shelve (required by Flower for state persistence)
RUN --mount=type=cache,target=/var/cache/apt,sharing=locked \
    --mount=type=cache,target=/var/lib/apt,sharing=locked \
    apt-get update && apt-get install -y --no-install-recommends \
    python3-gdbm \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Create non-root user for security
RUN groupadd -r appuser && useradd -r -g appuser appuser

# Copy only application code (no Chromium, no build tools)
COPY --chown=appuser:appuser . /code/

# Create data directory for Flower
RUN mkdir -p /data && chown appuser:appuser /data

# Switch to non-root user
USER appuser

# Default command (override for specific service)
CMD ["celery", "--app", "config.celery", "beat", "--loglevel", "info", "--scheduler", "django_celery_beat.schedulers:DatabaseScheduler"]

# =============================================================================
# Stage 5: Celery Worker (separate from Beat)
# Requires Chromium for Lighthouse audits and screenshot generation
# =============================================================================
FROM runtime-full AS celery-worker

# Override healthcheck from runtime-full - celery doesn't expose HTTP
HEALTHCHECK NONE

# Switch back to root to copy and set permissions
USER root

# Copy celery-specific entrypoint with correct permissions
COPY --chown=appuser:appuser --chmod=755 deployment/docker-entrypoint-celery.sh /docker-entrypoint-celery.sh

# Switch back to non-root user
USER appuser

# Override entrypoint for celery (no migrations/collectstatic needed)
ENTRYPOINT ["/docker-entrypoint-celery.sh"]

# Run Celery worker only (Beat runs in separate container)
CMD ["celery", "--app", "config.celery", "worker", "--loglevel", "info", "--concurrency", "4"]

# =============================================================================
# Stage 6: Celery Beat Scheduler (separate from Worker)
# Lightweight container - no Chromium needed
# =============================================================================
FROM runtime-minimal AS celerybeat

# Default command runs the beat scheduler with database backend
CMD ["celery", "--app", "config.celery", "beat", "--loglevel", "info", "--scheduler", "django_celery_beat.schedulers:DatabaseScheduler"]

# =============================================================================
# Stage 7: Flower (Celery Monitoring)
# Lightweight container - no Chromium needed
# =============================================================================
FROM runtime-minimal AS flower

EXPOSE 80

# Flower health check endpoint
HEALTHCHECK --interval=30s --timeout=10s --start-period=30s --retries=3 \
    CMD curl -f http://127.0.0.1:80/healthcheck || exit 1

# Flower monitoring dashboard with persistence
# Initialize gdbm file first (Python 3.13 shelve can't create new dbm files)
CMD ["sh", "-c", "python -c \"import dbm.gnu; dbm.gnu.open('/data/flower.db', 'c').close()\" && celery --app config.celery flower --port=80 --persistent=true --db=/data/flower.db"]

# =============================================================================
# Stage 9: Unified Celery (Worker + Beat combined) - DEPRECATED
# Not recommended due to Docker nofile limit issues with -B flag
# See: https://github.com/celery/celery/issues/8306
# =============================================================================
FROM runtime-full AS celery-unified

# Override healthcheck from runtime-full - celery doesn't expose HTTP
HEALTHCHECK NONE

# Switch back to root to copy and set permissions
USER root

# Copy celery-specific entrypoint with correct permissions
COPY --chown=appuser:appuser --chmod=755 deployment/docker-entrypoint-celery.sh /docker-entrypoint-celery.sh

# Switch back to non-root user
USER appuser

# Override entrypoint for celery (no migrations/collectstatic needed)
ENTRYPOINT ["/docker-entrypoint-celery.sh"]

# Run Celery worker with Beat scheduler included (-B flag)
# Note: Using prefork pool (default) because -B doesn't work with gevent
# Adjust concurrency based on your needs (default is number of CPUs)
CMD ["celery", "--app", "config.celery", "worker", "--beat", "--loglevel", "info", "--concurrency", "4", "--scheduler", "django_celery_beat.schedulers:DatabaseScheduler"]

# =============================================================================
# Stage 10: Test Image (skips JS build)
# =============================================================================
FROM builder AS test
ARG SKIP_JS_BUILD=1
# Inherits from builder but with SKIP_JS_BUILD=1 for faster test builds
